		    +---------------------------+
		    |             OS            |
		    | PROJECT 3: VIRTUAL MEMORY |
		    |      DESIGN DOCUMENT      |
		    +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Kevin Vong <s8kevong@stud.uni-saarland.de>
Kaleem Ullah <s8kaulla@stud.uni-saarland.de>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

https://cs.stackexchange.com/questions/24011/clock-page-replacement-algorithm-already-existing-pages

http://www.cs.utexas.edu/users/witchel/372/lectures/16.PageReplacementAlgos.pdf

			PAGE TABLE MANAGEMENT
			=====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In page.h:

struct spt_record {
  void *user_page;
 
  uint8_t status;
  bool dirty;
  bool pinned;
  
  // Swap stuff
  size_t swap_index;

  // Filesys stuff
  struct file *file;
  off_t offset;
  size_t read_bytes;
  size_t zero_bytes;
  bool writable;

  void *frame_addr;

  struct hash_elem hash_ele;
};
Used as an entry in the spt, with info about the user page.

In thread.h:

    struct hash *sup_pt;

Each process has its own supplementary page table, so we put it in struct thread.

---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

In spt_load, we attempt to locate the given user page in our supplementary page table.
First, we lookup the page to find its entry in our spt; then, we check the status of
page. This tells us whether the page is an all zero page, on a frame already, on swap,
or on a file. From there, we proceed differently according to the status.
If the page is an all zero page, we allocate a frame by calling allocFrame. This function
attempts to obtain a frame to store the user page; if palloc_get_page fails, then it
evicts a page using the clock algorithm, and returns a frame address. We use this address
to store the user page by zeroing out all the bits.
If the page is on a frame already, we just return the frame address that was located in the
supplementary page table entry for the user page.
If the page is on swap, we obtain a frame using allocFrame, and load the data in from our
swap partition.
If the page is on a file, we obtain a frame using allocFrame, and read from the file. If
the file size is not a multiple of the pg size, then we zero out the rest of the page.

It's also important to note that when a frame is allocated for a user page, we store
the info in both our frame table and supplementary page table. This makes it very easy
to locate the frame that a user page is located on.

>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

When we obtain a frame to store a user page, we make sure to set the dirty bit to zero
since we are storing a new page onto it. If we ever have to write the dirty page back to a file,
like when we are unmapping memory mapped files, we check if either the kernel or user page
is dirty. For accessed bits, we only need to check if the user accesses their page for
our eviction algorithm; if a page hasn't been accessed in a while by a user, then we evict
the page and use the frame for another page.

---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?

When two processes need a new frame at the same time, races are avoided by
a mutex lock that is grabbed as soon as a process attempts to allocate a frame.
Since only one process will have the lock and be able to allocate/evict a frame,
a race will never occur.

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?

We chose a hash table due to its efficiency and speed, especially when
storing a large number of elements. The example of a hash table in the reference
guide also seemed like a perfect fit for our supplementary page table, so that
played a role in our choice as well.

		       PAGING TO AND FROM DISK
		       =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In frame.h:

struct ft_record {
  void *frame_addr; // frame, created with palloc
  void *user_page; // virtual page occupying the frame
  struct thread *owner; // current thread owner of this frame
  struct hash_elem hash_ele; // hash table element
  struct list_elem list_ele; //for clock algo
  bool pin;
};

An entry in our frame table. Keeps track  of addresses and pinned status.

In frame.c:

static struct hash frame_table;

Our frame_table; a global variable since all user processes must share
the pool of frames.

static struct lock mutex;

A lock used to avoid synchronization problems when allocating or evicting frames.

static struct list frame_list;

A linked list of frames, used in our clock algorithm eviction policy.

static struct list_elem *clock;

The "clock hand" in our clock algorithm, which points towards a potential
frame to be evicted.

In thread.h:

uint8_t current_esp;

Keeps track of the thread's current stack pointer; used in case the kernel thread
has a page fault.

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

To evict a frame, we begin iterating through our frame_list. As we check
every frame, we check two things: whether the frame is pinned, and whether the
frame has been accessed since we last checked it. If a frame is pinned, we
leave it alone. If the frame has been accessed, we set its accessed bit to
zero and continue. This gives the frame a "second chance," but if the frame has
not been accessed by the time we check it again, then we will evict it.

When evicting a page from a frame, we add it to our swap table, update its entry 
in our supplementary page table, and free its frame. 
We then allocate a new frame, inserting an entry into our frame table for it, 
and return the address of the frame to the process that needed it.

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

In our allocFrame method, we call pagedir_clear_page to remove the link between the
user virtual page and the frame page. We then call spt_addSwap and spt_setDirty after 
evicting process Q's page from the frame. This updates the supplementary page table's 
entry to note that the page has been moved to swap, and also marks whether or not the
page is dirty. Lastly, we remove the frame table entry to reflect the fact that
Q's page no longer resides in the frame.

>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

If a we hit a page fault for an invalid virtual address, we check if the fault address
is either above the stack pointer, or 4 or 32 bytes below the stack pointer (like with
a PUSH or PUSHA instruction). If so, then we could potentially grow the stack. We then
check if the faulting address would not cause the stack to grow over 8MB, and if the 
faulting address is within the PHYS_BASE bound. If these hold true, then we allocate
a new zeroed out frame to grow the stack.

---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

When a process needs a frame, it grabs a mutex lock while the frame table
works to allocate a frame for the process. While it is holding this lock,
it does not request any other resources. Since it doesn't request any other
resources, it won't wait for another process to release resources. This prevents
the 2nd and 4th conditions for deadlocking, namely the hold & wait condition
and the circular wait condition. The same can be said for all the other methods
that acquire the mutex lock, such as when a frame is freed, deleted, or pinned. The
process will never be holding a resource while waiting for another resource to be
freed, so this prevents our frame table from dead locking.

>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

While Q's frame is being evicted, it can access the frame up until the point that
we clear its pagedir entry. From there, any access to the page will fault. In our
page fault handler, we call the spt_load function, which then calls the allocFrame
function. However, the allocFrame function always attempts to acquire a lock before
beginning any allocation or eviction. Thus, if P is currently evicting Q's frame and
Q faults on accessing that page, Q must wait for P to finish evicting its frame because
of the mutex lock. This prevents any weird race conditions from happening when
a process evicts another process's frame.

>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

This case is handled in spt_load. When we allocate a frame to a page,
we also "pin" the frame so our eviction policy will know not to evict
the frame. While we have the frame pinned, we read the page in from
the file system or swap. This ensures that the frame that we are reading
the page into is protected from our eviction policy.

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

During system calls, we call the valid_ptr function to check whether
or not an address is valid before we attempt to access it. Inside of
our valid_ptr function, we check if the pointer is a user virtual
address and if it is within the bounds of the user virtual address
space. If so, then we handle it in the same way that our page fault
handler does: by attempting to load in the page using spt_load, or
potentially growing the stack. If we cannot load the page or grow
the stack, then we exit with an error because the pointer is invalid.

---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

Our design really only has two forms of locking: a mutex lock for
changing, adding, or deleting entries in our frame table, and a pinning
system, as suggested by the project documentation, to prevent a frame
from being evicted when it is being loaded. This means that we have
more parallelism than a single lock system by having a more fine-grained
locking system. On the other hand, we also have less possibility for
deadlocking because we only have two locks -- this keeps things simple
for us. We designed our locking system in this way because of the
recommendations in the project specs, as well as our own desire to
keep the synchronization as simple as possible.

			 MEMORY MAPPED FILES
			 ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In thread.h:

struct list mmapList;

A list of memory mapped files. Used to track files and unmap them
when the process exits.

struct mmap_record
{
  int id;
  struct file *file;
  void *user_addr;
  size_t file_size;

  struct list_elem elem;
};

An element in our mmapList. Keeps track of useful information about
the memory mapped file.

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

In our virtual memory system, memory mapped file pages are treated
like pages whose contents are found in a file (STATUS_FILE). Thus,
the page information in our supplementary page table is identical
to any other page that is located in a while. This means that
even page faults and page eviction is handled in the same way, but
we take special care to mark whether or not the page has been modified
or not. If it has, then our entry in the supplementary page table reflects
this, and is used to determine whether or not we need to write back
to the file. This is seen in our spt_unmapFile function, where we
check the dirty status, potentially load in from swap, and write the
page back to its original file.

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

In our mmap system call function, we check the user provided address
with the size of the file that is to be memory mapped. We check every
page that will be occupied by the file, using a for loop bounded by the
file size. If any of these pages is found in our supplementary page table,
then we know that the virtual address segment is already being used, and we
cannot memory map the file to this address -- preventing overlap of existing
virtual address segments.

---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

Our implementation shares a lot of the code for executable file pages and
memory mapped file pages. This cuts down on a lot of redudant code, which
saved us a lot of effort. The only difference is when a process exits and
these memory mapped files are unmapped, since we actually need to check
if the pages are dirty and write them back to the file if so. Thus, our
implementation shares much of the code for the two situations, but still
takes care to treat the two situations differently when it comes to
actually writing the pages back to the files.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
